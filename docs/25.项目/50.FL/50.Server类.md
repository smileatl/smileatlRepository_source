---
title: Server类
date: 2023-08-11 11:33:32
permalink: /pages/03a9fb/
categories:
  - 项目
  - FL
tags:
  - 
author: 
  name: smileatl
  link: https://github.com/smileatl
---
# Server类

一个服务器创建一个Server类，用于维护该进程的全局模型

```python
class Server():
    # 构造方法__init__()会在类实例化时自动调用。无论构造方法还是其他方法都需要
    # 将self作为第一个参数，它代表类的实例。
    def __init__(self) -> None:
        pass  # 空语句，让代码整体完整，如果定义一个函数里面为空，就会报错

    # 自定义方法
    def run(self, data, label):  # data:ndarray:(10000,28,28,1),label:ndarray:(10000,)
        # __定义私有属性、私有方法、私有对象
        self.__comm = CommServer('127.0.0.1', params.port, params.CLIENT_NUM)

        # 初始化了训练模型
        # 这个就是服务器Server里的global model
        # 优化器adam，损失函数：SparseCategoricalCrossentropy
        # 结构：该模型包含一个平坦层，输入维数为（28，28）；包含128个神经元的完全连接层，由Relu功能激活；
        # 比例为0.2的层dropout层；以及包含10个神经元的全连接输出层，由Softmax函数激活。
        self.__trainer = TR()

        # import matlab.engine
        # # 启动一个matlab的进程
        # eng = matlab.engine.start_matlab()

        loss_recorder = []
        acc_recorder = []
        mse_recorder = []
        mae_recorder = []
        mape_recorder = []
        iter_recorder = []
        # 上行链路通信延迟
        uplink_delay_recorder = []
        schedualed_user_info = {}
        # 上行链路通信延时累加
        uplink_delay_cost = []

        plt.rcParams['font.sans-serif'] = ['SimHei']  # 解决中文字符乱码的问题
        # plt.figure(figsize=(8, 6), dpi=80)
        # 一次性在figure上创建3*2的网格
        # f, axes = plt.subplots(3, 2)
        # for ax in axes[:, 0]:
        #     ax.remove()
        # axes = axes[:, 1]
        # gs = axes[0].get_gridspec()
        # axbig = f.add_subplot(gs[:, 0])
        # plt.ion()

        for iter in range(params.ITERATION_NUM):
            print('************************************ ITERATION {} *****************************************'.format(iter))
            # 获取 global model 的权重
            self.__global_model = self.__trainer.get_weights()
            # 向每一个用户下发 global model
            # 基站向参与训练的用户广播用来初始化训练模型的信息。然后各个用户根据收到的信息初始化各自的模型。
            # 这里是发给所有用户
            print('delivering global model ...')
            self.__comm.broadcast(self.__global_model)
            # 接收每个用户的梯度范数
            # 收到了用户所有的信息，有{'grad_norm': 1.2053706939332187, 'received_power': 0.0011136735073575378,
            # 'position': [-3.1623161309340726, 29.798137378666535]}}
            # 这里是接收所有用户的
            msg = self.__comm.recv_all()
            print('gradient received ...')

            # ********************************************************************************
            # 这一段是用户调度和资源分配分离的优化算法
            # 基于梯度范数给出调度结果
            # sche_sig, a = select_based_on_weight(msg)
            # sche_sig, a = random_select() # 随机调度
            # 给出资源分配结果
            # RB_sche, user_delay, iter_delay = get_RB_schedual(eng, msg, sche_sig)
            # RB_sche, user_delay, iter_delay = random_RB_schedual(msg, sche_sig) # 随机分配
            # *********************************************************************************

            # 用户调度和资源分配联合的优化算法
            # sche_sig:用户调度结果, a:被调度用户的id列表, RB_sche：资源RB分配,
            # user_delay：每一个用户上行链路通信延迟, iter_delay：迭代延迟，也就是在所有被调度用户中的最大延时（最大更新延迟：
            # 包括上行链路通信延时和本地训练耗时，本地训练时间在当前场景下设定为常数）
            '''其实这里的iter_delay还没有考虑计算耗时，而只有上行两路通信延迟'''
            # 程序里面没有用到RB_sche，user_delay
            sche_sig, a = random_select()
            RB_sche, user_delay, iter_delay = random_RB_schedual(msg, sche_sig)
            # print(sche_sig)     # {0: 1, 1: 0, 2: 0, 3: 1}
            # print(a)            # [0,3]
            # print(RB_sche)      # array [1,0,0,0]
            # print(user_delay)   # array [0.60815446,-0,-0,0.13260304]
            # print(iter_delay)   # 0.60815446
            # print("schedualed user num : ", len(a))
            # 下发调度结果
            print('sending schedual command ...')
            self.__comm.send(sche_sig)
            # 接收被调度用户的 local model
            # 只有被调度用户才更新模型，才向服务器send local model
            # 只接收（a：被调度用户id列表里的用户）的local model
            local_models = self.__comm.recv(list(a))
            print('local models received ...')
            sys.stdout.flush()
            # 融合模型
            self.__trainer.aggregate(local_models)

            """
            # 评估当前模型
            eval_result = self.__trainer.evaluate(data, label)
```

