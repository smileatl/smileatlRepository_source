---
title: 主程序
date: 2023-08-11 11:33:32
permalink: /pages/0fdbb3/
categories:
  - 项目
  - FL
tags:
  - 
author: 
  name: smileatl
  link: https://github.com/smileatl
---
# 主程序

## 导入必要的模块和类

这段代码主要进行了一个分布式深度学习模型的训练和评估过程，涉及到服务器和多个客户端的协同工作。下面是对代码中主要步骤的详细注释：

```python
import multiprocessing as mp
import numpy as np
import pandas as pd
from function import *
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

import params

from Client import Client
from Server import Server
```

## 创建服务器和客户端实例：

```python
server = Server()  # 创建一个Server实例
clients = []
# 创建params.CLIENT_NUM个Client实例并存储在clients列表中
for _ in range(params.CLIENT_NUM):
    clients.append(Client(_))
```

## 数据预处理和划分：

```python
lookback = 50  # 定义回溯窗口的大小

# 读取流量文件的第3列数据，进行最大最小归一化
data = pd.read_csv('./FP/data_inttraffic(0-7).csv', usecols=[3])
scaler_minmax = MinMaxScaler()  # 创建MinMaxScaler对象
data = scaler_minmax.fit_transform(data)  # 对数据进行最大最小归一化

d = []
# 创建包含回溯窗口的数据集，用于训练和测试
for i in range(data.shape[0] - lookback):
    d.append(data[i:i + lookback + 1])
d = np.array(d)

# 创建训练数据集和测试数据集，返回x_train, y_train, x_test, y_test以及d（所有流量数据）
split_rate = 2/3
x_train, y_train, x_test, y_test, d = create_dataset(data, lookback, split_rate)

 week_length = int(np.floor(data.shape[0] / 7))  # 将数据集划分成7周的长度
```

## 设置随机种子并创建进程锁：

```python
np.random.seed(2)  # 设置随机种子以保持一致的随机性

# 获取进程锁，用于后续将结果写入CSV文件时的同步
lock = mp.Lock()
```

## 创建服务器与客户端进程

以下是对给定代码段的详细注释：

```python
# 导入所需库和模块
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import multiprocessing as mp

# 创建服务器进程，传入测试数据x_test和标签y_test，通过server.run方法运行
server_p = mp.Process(target=server.run, args=(x_test, y_test))
clients_p = []

# 在训练前划分各个用户的训练集和测试集的数据集部分，通过week_length大小进行划分
for i in range(params.CLIENT_NUM):
    # 读取各个客户端的流量数据
    data0 = pd.read_csv('./FP/data_inttraffic(0-7)' + str(i + 1) + '.csv', usecols=[3])
    scaler_minmax = MinMaxScaler()
    data0 = scaler_minmax.fit_transform(data0)  # 对数据进行最大最小归一化

    d_i = []
    # 创建包含回溯窗口的数据集，用于客户端i的训练和测试
    for a in range(data0.shape[0] - lookback):
        d_i.append(data0[a:a + lookback + 1])
    d_i = np.array(d_i)

    # 划分训练集和测试集
    [x_train_i, y_train_i] = d_i[:6 * week_length, :-1, :], d_i[:6 * week_length, -1, :]
    [x_test_i, y_test_i] = d_i[(6 * week_length): (7 * week_length), :-1], d_i[(6 * week_length): (7 * week_length), -1]

    # 创建客户端进程，传入客户端i的训练和测试数据，以及其他参数，通过clients[i].run方法运行
    clients_p.append(mp.Process(target=clients[i].run, args=(
        x_train_i,
        y_train_i,
        x_test_i,
        y_test_i,
        scaler_minmax,
        [[np.random.uniform(0, 100), np.random.uniform(0, 2 * np.math.pi)],
         [np.random.uniform(3, 5), np.random.uniform(0, 2 * np.math.pi)]],
        lock
    )))
```

这段代码实现了一个分布式的客户端-服务器模型，用于处理流量数据的训练和测试。以下是对各个部分的详细解释：

1. 创建服务器进程：
   - 使用`mp.Process`创建一个新的进程 `server_p`，该进程将运行 `server.run` 方法，参数为 `x_test` 和 `y_test`，即测试数据和标签。

2. 创建客户端进程：
   - 使用循环遍历每个客户端编号，从1到`params.CLIENT_NUM`。
   - 读取客户端的流量数据文件（CSV格式），仅读取第4列数据（使用 `usecols=[3]`）。
   - 使用 `MinMaxScaler` 对数据进行最大最小归一化，将数据范围缩放到[0, 1]。
   - 创建回溯窗口数据集 `d_i`，在数据集上滑动窗口，每个窗口包含历史数据和对应的下一个数据点。
   - 划分训练集和测试集，前6周的数据用于训练，第7周的数据用于测试。
   - 使用 `np.random.uniform` 生成随机参数用于客户端的训练。

3. 创建客户端进程列表：
   - 使用 `mp.Process` 创建一个进程列表 `clients_p`，每个进程运行 `clients[i].run` 方法，传入客户端的训练和测试数据、归一化器、随机参数等。

这段代码的目的是通过多进程实现分布式的流量数据处理，其中服务器和客户端分别运行在不同的进程中，通过共享数据来进行训练和测试。



## 启动

以下是对给定代码段的详细注释：

```python
# 启动服务器进程和所有客户端进程
server_p.start()  # 启动服务器进程，使其开始执行 server.run 方法
for client_p in clients_p:
    client_p.start()  # 启动每个客户端进程，使其开始执行 clients[i].run 方法

# 等待服务器进程和所有客户端进程完成
server_p.join()  # 等待服务器进程执行完毕
for client_p in clients_p:
    client_p.join()  # 等待每个客户端进程执行完毕
```

这段代码实现了服务器和所有客户端进程的启动和等待操作，确保它们按照预期顺序执行并完成。以下是各个部分的详细解释：

1. 启动服务器进程和客户端进程：
   - 使用 `start()` 方法启动服务器进程 `server_p`，使其开始执行在之前代码中定义的 `server.run` 方法，该方法用于服务器的运行和处理。
   - 使用循环遍历客户端进程列表 `clients_p`，对每个客户端进程使用 `start()` 方法启动，使其开始执行相应客户端的 `clients[i].run` 方法，用于客户端的训练和处理。

2. 等待服务器进程和客户端进程完成：
   - 使用 `join()` 方法等待服务器进程 `server_p` 完成执行，即等待服务器的运行和处理操作完成。
   - 使用循环遍历客户端进程列表 `clients_p`，对每个客户端进程使用 `join()` 方法等待其完成执行，确保所有客户端的训练和处理操作都已完成。

这段代码的目的是确保服务器和所有客户端进程按照预期顺序启动、执行和完成，以实现分布式的训练和测试过程，并在所有进程完成后继续执行主程序的后续操作。这种方式能够有效利用多核处理器的并行能力，提高训练和处理的效率。

服务器和各个客户端是并行独立运行的，而不是在一起执行。

## 总结

这段代码主要进行了一个分布式深度学习模型的训练和评估过程，涉及到服务器和多个客户端的协同工作。下面是对代码中主要步骤的详细注释：

```python
import multiprocessing as mp
import numpy as np
import pandas as pd
from function import *  # 导入自定义的函数
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

import params

from Client import Client  # 导入自定义的Client类
from Server import Server  # 导入自定义的Server类

if __name__ == '__main__':
    # 创建一个Server实例
    server = Server()
    clients = []
    # 创建params.CLIENT_NUM个Client实例并存储在clients列表中
    for _ in range(params.CLIENT_NUM):
        clients.append(Client(_))

    lookback = 50  # 定义回溯窗口的大小

    # 读取流量文件的第3列数据，进行最大最小归一化
    data = pd.read_csv('./FP/data_inttraffic(0-7).csv', usecols=[3])
    scaler_minmax = MinMaxScaler()  # 创建MinMaxScaler对象
    data = scaler_minmax.fit_transform(data)  # 对数据进行最大最小归一化

    d = []
    # 创建包含回溯窗口的数据集，用于训练和测试
    for i in range(data.shape[0] - lookback):
        d.append(data[i:i + lookback + 1])
    d = np.array(d)

    # 创建训练数据集和测试数据集，返回x_train, y_train, x_test, y_test以及d（所有流量数据）
    split_rate = 2/3
    x_train, y_train, x_test, y_test, d = create_dataset(data, lookback, split_rate)

    np.random.seed(2)  # 设置随机种子以保持一致的随机性

    # 创建服务器进程，传入测试数据x_test和标签y_test，通过server.run方法运行
    server_p = mp.Process(target=server.run, args=(x_test, y_test))
    clients_p = []

    week_length = int(np.floor(data.shape[0] / 7))  # 将数据集划分成7周的长度

    # 获取进程锁，用于后续将结果写入CSV文件时的同步
    lock = mp.Lock()

    # 在训练前划分各个用户的训练集和测试集的数据集部分，通过week_length大小进行划分
    for i in range(params.CLIENT_NUM):
        # 读取各个客户端的流量数据
        data0 = pd.read_csv('./FP/data_inttraffic(0-7)' + str(i + 1) + '.csv', usecols=[3])
        scaler_minmax = MinMaxScaler()
        data0 = scaler_minmax.fit_transform(data0)  # 对数据进行最大最小归一化

        d_i = []
        # 创建包含回溯窗口的数据集，用于客户端i的训练和测试
        for a in range(data0.shape[0] - lookback):
            d_i.append(data0[a:a + lookback + 1])
        d_i = np.array(d_i)

        # 划分训练集和测试集
        [x_train_i, y_train_i] = d_i[:6 * week_length, :-1, :], d_i[:6 * week_length, -1, :]
        [x_test_i, y_test_i] = d_i[(6 * week_length): (7 * week_length), :-1], d_i[(6 * week_length): (7 * week_length), -1]

        # 创建客户端进程，传入客户端i的训练和测试数据，以及其他参数，通过clients[i].run方法运行
        clients_p.append(mp.Process(target=clients[i].run, args=(
            x_train_i,
            y_train_i,
            x_test_i,
            y_test_i,
            scaler_minmax,
            [[np.random.uniform(0, 100), np.random.uniform(0, 2 * np.math.pi)],
             [np.random.uniform(3, 5), np.random.uniform(0, 2 * np.math.pi)]],
            lock
        )))

    # 启动服务器进程和所有客户端进程
    server_p.start()
    for client_p in clients_p:
        client_p.start()

    # 等待服务器进程和所有客户端进程完成
    server_p.join()
    for client_p in clients_p:
        client_p.join()
```



## 完整代码

```python
import multiprocessing as mp
import numpy as np
import pandas as pd
from function import *
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

import params

from Client import Client
from Server import Server


if __name__ == '__main__':
    server = Server()  # 这句只执行了__init__
    clients = []
    # 创建5个Client
    for _ in range(params.CLIENT_NUM):  # _就是平时i的作用，它不在意变量的值，只用于循环遍历n次
        clients.append(Client(_))

    lookback = 50
    # 读取流量文件，使用索引为3的列，也就是我把流量的数值缩放到0-7的那一列
    data = pd.read_csv('./FP/data_inttraffic(0-7).csv', usecols=[3])

    # 用最大最小归一化这类创建一个scaler_minmax
    scaler_minmax = MinMaxScaler()
    # 这个类里面有一个fit_transform函数，可以把数据从0-7进行最大最小归一化，缩放到0-1
    data = scaler_minmax.fit_transform(data)

    d = []
    for i in range(data.shape[0] - lookback):
        d.append(data[i:i + lookback + 1])
    d = np.array(d)

    # 创建训练数据集，返回训练数据和所有数据
    split_rate = 2/3 # 测试集在数据集中的比例
    x_train, y_train, x_test, y_test, d = create_dataset(data, lookback, split_rate)# d为全部流量数据

    # seed( ) 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed( )值，则每次生成的随即数都相同
    # 从每堆种子里选出来的数都是不会变的，从不同的堆里选随机种子每次都不一样,每次都seed(2)生成的数会是一样的
    np.random.seed(2)

    # multiprocessing多进程模块，Process创建进程的类
    # target：调用对象/目标函数，args：调用对象的位置参数元组 / 按位置给目标函数传参
    # Server.run的两个输入参数：data，label
    # server_p只有一个进程

    server_p = mp.Process(target=server.run, args=(x_test, y_test))
    clients_p = []

    # local_data_size=60000/20=3000,每个终端用户包括3000个训练样本
    week_length = int(np.floor(data.shape[0] / 7)) # 数据集划分成七周，一周一份，记录长度
    d_i = []

    # 获取进程锁，用以后续转换result为csv文件时的同步
    lock = mp.Lock()

    # 在训练前划分各个用户的训练集和测试集在中的数据集中的部分，通过week_length的大小划分
    for i in range(params.CLIENT_NUM):
        # 分别定义训练集和测试集

        # 读取各个csv文件数据
        data0 = pd.read_csv('./FP/data_inttraffic(0-7)' + str(i + 1) + '.csv', usecols=[3])

        scaler_minmax = MinMaxScaler()
        # 这个类里面有一个fit_transform函数，可以把数据从0-7进行最大最小归一化，缩放到0-1
        data0 = scaler_minmax.fit_transform(data0)

        d_i = []
        for a in range(data0.shape[0] - lookback):
            d_i.append(data0[a:a + lookback + 1])
        d_i = np.array(d_i)

        [x_train_i, y_train_i] = d_i[:6 * week_length, :-1, :], d_i[:6 * week_length, -1, :]
        [x_test_i, y_test_i] = d_i[(6 * week_length): (7 * week_length), :-1], d_i[(6 * week_length): (7 * week_length), -1]

        clients_p.append(mp.Process(target=clients[i].run, args=(

            x_train_i,
            y_train_i,
            x_test_i,
            y_test_i,
            scaler_minmax,
            [[np.random.uniform(0, 100), np.random.uniform(0, 2 * np.math.pi)],
             [np.random.uniform(3, 5), np.random.uniform(0, 2 * np.math.pi)]],
            lock
        )))


    # np.random.uniform(low,high,size)从一个均匀分布[low,high)中随机采样,size输出样本数目，缺省时输出1个值
    # 返回值：ndarray类型，其形状和参数size中描述一致。
    # result = classify_dataset(data, label)
    # np.random.seed(4)
    # server_p = mp.Process(target=server.run, args=(edata, elabel))
    # clients_p = []
    # for i, client in enumerate(clients):
    #     clients_p.append(mp.Process(target=client.run, args=(
    #         result[i],
    #         i * np.ones((len(result[i]),), dtype=np.uint8),
    #         [[np.random.uniform(0, 100), np.random.uniform(0, 2*np.math.pi)],
    #          [np.random.uniform(3, 5), np.random.uniform(0, 2*np.math.pi)]]
    #     )))

    # # .start启动某一个进程
    server_p.start()
    for client_p in clients_p:
        client_p.start()


    # .join阻塞住主进程，等待子进程结束后，然后再往下执行
    server_p.join()
    for client_p in clients_p:
        client_p.join()


   
```

